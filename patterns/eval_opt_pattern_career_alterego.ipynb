{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ffcb21",
   "metadata": {},
   "source": [
    "## Evaluator-optimizer\n",
    "\n",
    "In evaluator-optimizer workflows, one LLM call creates a response and the other evaluates that response. If the evaluator or a human-in-the-loop determines the response needs refinement, feedback is provided and the response is recreated. This loop continues until an acceptable response is generated.\n",
    "\n",
    "<img src=\"../assets/eval_optimizer_workflow.png\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ddec3",
   "metadata": {},
   "source": [
    "###  CareerAlterEgo Chatbot App \n",
    "    \n",
    "This app makes use of the above pattern.\n",
    "Feed your linkedin profile pdf ( in folder project-root/assets/my_linked_profile) and any additional details about your career profile in summary.txt file and the agent will respond to career related queries grounded with the information that you provided. \n",
    "- For questions the agent does n't have a proper response, such questions are recorded as telegram messages and sent to your telegram channel via tool call. \n",
    "- For future followup with prospective clients or future employers, the agent records the email address of the chat user when provided and sends as a telegram message.\n",
    "\n",
    "#### Key highlights :\n",
    "- trims the chat history from gradio to only lastest 3 Q&A pair\n",
    "- avoids infinite tool calling loop or infinite generate-evaluate loop by keeping track of tool call counts and regenerate request counts\n",
    "\n",
    "<img src=\"../assets/career_alterego_workflow.png\" width=400/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef796c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming notebook is in notebooks/ folder\n",
    "project_root = Path().resolve().parent  # adjust if needed\n",
    "sys.path.append(str(project_root))\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"../assets/my_linkedin_profile/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e71274",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/my_linkedin_profile/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"Rabba Alam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AnyMessage\n",
    "from typing_extensions import TypedDict,Annotated\n",
    "from operator import add\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    chat_history_from_gradio: list[AnyMessage]\n",
    "    messages_per_user_question: Annotated[list[AnyMessage], add]\n",
    "    is_accepted: bool\n",
    "    feedback: str\n",
    "    response_regenerate_count: int\n",
    "    tool_call_count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "generator_llm = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\", temperature=0)\n",
    "evaluator_llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e386898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from utils.telegram import send_message\n",
    "\n",
    "@tool\n",
    "def record_user_details(email, name=\"<name not provided>\" , notes=\"<notes not provided>\"):\n",
    "    \"\"\"\n",
    "    Record a user's contact details when they express interest in staying in touch.\n",
    "\n",
    "    Use this tool when the user provides an email address or clearly indicates\n",
    "    they want to be contacted in the future (for follow-ups, updates, or further discussion).\n",
    "\n",
    "    Args:\n",
    "        email (str): The user's email address. This is required and must be a valid email.\n",
    "        name (str, optional): The user's name if provided in the conversation.\n",
    "            Use \"Name not provided\" if the user does not mention their name.\n",
    "        notes (str, optional): Any additional context or intent expressed by the user,\n",
    "            such as why they want to stay in touch or what they are interested in.\n",
    "\n",
    "    Returns:\n",
    "        dict: A confirmation object indicating the user's details were recorded.\n",
    "            Example:\n",
    "                {\"recorded\": \"ok\"}\n",
    "\n",
    "    Output rules:\n",
    "    - Do not explain the tool call\n",
    "    - Do not add conversational text\n",
    "    - Call this tool directly with extracted values\n",
    "\n",
    "    \"\"\"\n",
    "    send_message(f\"Recording interest from : \\n Name : {name} \\n Email : {email} \\n Notes : {notes}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "@tool\n",
    "def record_unknown_question(question):\n",
    "    \"\"\"\n",
    "    Record a user question that the agent could not confidently answer.\n",
    "\n",
    "    Use this tool whenever the agent does not know the correct answer,\n",
    "    is unsure about the accuracy of its response, or lacks sufficient\n",
    "    information to provide a reliable reply.\n",
    "\n",
    "    This tool should be used instead of guessing or hallucinating an answer.\n",
    "    The purpose is to capture unanswered questions for later review,\n",
    "    knowledge base expansion, or human follow-up.\n",
    "\n",
    "    Args:\n",
    "        question (str): The exact question asked by the user that the agent\n",
    "            could not answer confidently.\n",
    "\n",
    "    Returns:\n",
    "        dict: A confirmation object indicating the question was recorded.\n",
    "            Example:\n",
    "                {\"recorded\": \"ok\"}\n",
    "\n",
    "    Output rules:\n",
    "    - Do not explain the tool call\n",
    "    - Do not add conversational text\n",
    "    - Call this tool directly with extracted values\n",
    "\n",
    "    Notes:\n",
    "        - Always prefer using this tool over providing an uncertain or speculative answer.\n",
    "        - Do NOT modify or rephrase the user's question before recording it.\n",
    "\n",
    "    \"\"\"\n",
    "    send_message(\n",
    "        \"Recording question asked that I couldn't answer.\\n\"\n",
    "        f\"Question:\\n{question}\"\n",
    "    )\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \\\n",
    "If you sense the conversion is about to end then try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool.\\\n",
    "Do not ask for email again if the user has has already provided their email address \"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n",
    "\n",
    "Markdown(system_prompt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "\n",
    "def generate_career_response(state:MessagesState):\n",
    "    base_system_prompt = system_prompt\n",
    "    \n",
    "    if not state.get(\"is_accepted\",True):\n",
    "        messages_per_user_question = state.get('messages_per_user_question')\n",
    "        base_system_prompt += \"\\n\\n## Previous answer was rejected.\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "        base_system_prompt += f\"\\n## Question : {messages_per_user_question[0].content}\\n\"\n",
    "        base_system_prompt += f\"\\n## Your attempted answer:\\n{messages_per_user_question[-1].content}\\n\"\n",
    "        base_system_prompt += f\"\\n## Reason for rejection:\\n{state.get('feedback')}\\n\\n\"\n",
    "\n",
    "    preamble_messages = [SystemMessage(base_system_prompt)] + state.get(\"chat_history\", [])\n",
    "    messages = state.get('messages_per_user_question')\n",
    "\n",
    "    \n",
    "\n",
    "    pending_question = messages[0]\n",
    "\n",
    "\n",
    "\n",
    "    if not isinstance(messages[-1],ToolMessage):\n",
    "       messages = messages + [pending_question]\n",
    "    tools=[record_user_details,record_unknown_question]\n",
    "    response = generator_llm.bind_tools(tools).invoke(preamble_messages + messages)\n",
    "    return {\"messages_per_user_question\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_executor(state: MessagesState):\n",
    "    last_msg = state[\"messages_per_user_question\"][-1]\n",
    "\n",
    "    tool_messages = []\n",
    "\n",
    "    for tool_call in last_msg.tool_calls:\n",
    "        tool = {\n",
    "            \"record_unknown_question\": record_unknown_question,\n",
    "            \"record_user_details\": record_user_details,\n",
    "        }[tool_call[\"name\"]]\n",
    "\n",
    "        result = tool.invoke(tool_call[\"args\"])\n",
    "\n",
    "        tool_messages.append(\n",
    "            ToolMessage(\n",
    "                content=result,\n",
    "                tool_call_id=tool_call[\"id\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return {\"messages_per_user_question\": tool_messages, \"tool_call_count\": state.get(\"tool_call_count\", 0) + len(tool_messages)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_after_tool(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Forces the LLM to summarize / integrate tool outputs\n",
    "    WITHOUT allowing further tool calls.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = (\n",
    "        [SystemMessage(\n",
    "            \"You have already used all tools. \"\n",
    "            \"Respond to the user using the tool results below. \"\n",
    "            \"DO NOT call any tools.\"\n",
    "        )]\n",
    "        + state[\"chat_history\"]\n",
    "        + state[\"messages_per_user_question\"]\n",
    "    )\n",
    "\n",
    "    response = generator_llm.invoke(\n",
    "        messages,\n",
    "        tool_choice=\"none\"  # ðŸ”‘ CRITICAL\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"messages_per_user_question\": [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat_history(chat_history: list[AnyMessage]) -> str:\n",
    "    formatted = []\n",
    "    for msg in chat_history:\n",
    "        role = msg.__class__.__name__.replace(\"Message\", \"\")\n",
    "        formatted.append(f\"{role}: {msg.content}\")\n",
    "    return \"\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pydantic schema for evaluation\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable:bool = Field(description=\"Decide if the agent's response is acceptable\")\n",
    "    feedback:str = Field(description=\"If agent's response is not acceptable then provide feedback on how to improve it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response(state:MessagesState):\n",
    "    evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "       You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "       The Agent is playing the role of {name} and is representing {name} . \\\n",
    "       The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "       The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "    evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "    evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\"\n",
    "    messages_per_user_question = state.get('messages_per_user_question')\n",
    "    conversation = format_chat_history(state.get(\"chat_history\", []) + messages_per_user_question)\n",
    "   \n",
    "    user_prompt = f\"Here is the conversation between the User and the Agent: \\n\\n{conversation}\\n\\n\"\n",
    "    user_prompt += \"Evaluate the latest response, replying with whether it is acceptable and your feedback.\"\n",
    "\n",
    "    input_to_evaluator = [SystemMessage(evaluator_system_prompt), HumanMessage(user_prompt)]\n",
    "\n",
    "    evaluation = evaluator_llm.with_structured_output(Evaluation).invoke(input_to_evaluator)\n",
    "\n",
    "    return { \"is_accepted\": evaluation.is_acceptable, \"feedback\": evaluation.feedback, \"response_regenerate_count\": state.get(\"response_regenerate_count\",0)+1}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "def route_based_on_evaluation(state:MessagesState) -> Literal[\"accepted\", \"rejected+feedback\"]:\n",
    "    MAX_REGENERATE_REQUESTS = 2\n",
    "    evaluation_success = state.get(\"is_accepted\", False)\n",
    "    response_regenerate_count = state.get(\"response_regenerate_count\", 1)\n",
    "    if evaluation_success or response_regenerate_count > MAX_REGENERATE_REQUESTS:\n",
    "        return \"accepted\"\n",
    "    else :\n",
    "        return \"rejected+feedback\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_generation(state:MessagesState)-> Literal[\"tool_executor\", \"evaluate_response\"]:\n",
    "    msg = state.get(\"messages_per_user_question\")[-1]\n",
    "    \n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        return \"tool_executor\"\n",
    "    return \"evaluate_response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_tool_execution(state:MessagesState) -> Literal[\"generate_career_response\", \"finalize_after_tool\"]:\n",
    "    MAX_TOOL_CALL_COUNT = 3\n",
    "    tool_call_count = state.get('tool_call_count',0)\n",
    "    if tool_call_count >= MAX_TOOL_CALL_COUNT :\n",
    "        return \"finalize_after_tool\"\n",
    "    return \"generate_career_response\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "agent_builder.add_node(\"generate_career_response\",generate_career_response)\n",
    "agent_builder.add_node(\"tool_executor\", tool_executor)\n",
    "agent_builder.add_node(\"finalize_after_tool\", finalize_after_tool)\n",
    "agent_builder.add_node(\"evaluate_response\",evaluate_response)\n",
    "\n",
    "agent_builder.add_edge(START, \"generate_career_response\")\n",
    "agent_builder.add_conditional_edges(\"generate_career_response\",route_after_generation,{\"tool_executor\":\"tool_executor\", \"evaluate_response\":\"evaluate_response\"})\n",
    "agent_builder.add_conditional_edges(\"tool_executor\", route_after_tool_execution, {\"generate_career_response\":\"generate_career_response\", \"finalize_after_tool\":\"finalize_after_tool\"})\n",
    "agent_builder.add_edge(\"finalize_after_tool\",\"evaluate_response\")\n",
    "agent_builder.add_conditional_edges(\"evaluate_response\",route_based_on_evaluation,{\"accepted\":END, \"rejected+feedback\":\"generate_career_response\"} )\n",
    "\n",
    "career_alterego_workflow = agent_builder.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af016c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import sys\n",
    "\n",
    "\n",
    "from utils.mermaid import save_and_render_langgraph_mermaid\n",
    "\n",
    "save_and_render_langgraph_mermaid(career_alterego_workflow,\"career_alterego_workflow.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387be45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage\n",
    "\n",
    "def extract_chat_history(history, max_turns=3):\n",
    "    chat_history = []\n",
    "\n",
    "    # Keep only last N user+assistant turns â†’ 2 * max_turns messages\n",
    "    recent = history[-2 * max_turns:]\n",
    "\n",
    "    for msg in recent:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            chat_history.append(HumanMessage(content=msg[\"content\"]))\n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            chat_history.append(AIMessage(content=msg[\"content\"]))\n",
    "\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    chat_history = extract_chat_history(history, max_turns=3)\n",
    "    response = career_alterego_workflow.invoke({\"chat_history\":chat_history, \"messages_per_user_question\": [HumanMessage(message)]})\n",
    "    return response[\"messages_per_user_question\"][-1].content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    title=\"Career AlterEgo Agent\",\n",
    "    description=\"An agentic AI career Q&A chatbot powered by LangGraph\",\n",
    "    chatbot=gr.Chatbot(height=450),\n",
    "    textbox=gr.Textbox(\n",
    "        placeholder=\"Ask about my career...\",\n",
    "        scale=7\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20795bd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
