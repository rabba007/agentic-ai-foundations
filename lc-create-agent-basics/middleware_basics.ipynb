{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df9ef94",
   "metadata": {},
   "source": [
    "### Middleware Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0950d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71609d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model_gemini_flash = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\", timeout=30, temperature=.5)\n",
    "model_llama_groq = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\", timeout=30, temperature=.5)\n",
    "model_gpt_4o_mini = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bbacc",
   "metadata": {},
   "source": [
    "### Summarize messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model_llama_groq,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[SummarizationMiddleware(\n",
    "        model=model_llama_groq,\n",
    "        trigger=(\"tokens\", 100),\n",
    "        keep=(\"messages\",1)\n",
    "    )]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"What is the capital of the moon?\"),\n",
    "        AIMessage(content=\"The capital of the moon is Lunapolis.\"),\n",
    "        HumanMessage(content=\"What is the weather in Lunapolis?\"),\n",
    "        AIMessage(content=\"Skies are clear, with a high of 120C and a low of -100C.\"),\n",
    "        HumanMessage(content=\"How many cheese miners live in Lunapolis?\"),\n",
    "        AIMessage(content=\"There are 100,000 cheese miners living in Lunapolis.\"),\n",
    "        HumanMessage(content=\"Do you think the cheese miners' union will strike?\"),\n",
    "        AIMessage(content=\"Yes, because they are unhappy with the new president.\"),\n",
    "        HumanMessage(content=\"If you were Lunapolis' new president how would you respond to the cheese miners' union?\"),\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5399c",
   "metadata": {},
   "source": [
    "### Trim/delete messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.agents.middleware import before_agent,AgentState\n",
    "from langchain.messages import ToolMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "@before_agent\n",
    "def trim_messages(state:AgentState, runtime:Runtime) -> dict[str,Any]|None:\n",
    "    \"Remove all the tool messages from the prompt\"\n",
    "    messages = state[\"messages\"]\n",
    "    tool_messages = [ m for m in messages if isinstance(m,ToolMessage)]\n",
    "    return {\"messages\":[RemoveMessage(id=m.id) for m in tool_messages]}\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model_llama_groq,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[trim_messages]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"My device won't turn on. What should I do?\"),\n",
    "        ToolMessage(content=\"blorp-x7 initiating diagnostic ping…\", tool_call_id=\"1\"),\n",
    "        AIMessage(content=\"Is the device plugged in and turned on?\"),\n",
    "        HumanMessage(content=\"Yes, it's plugged in and turned on.\"),\n",
    "        ToolMessage(content=\"temp=42C voltage=2.9v … greeble complete.\", tool_call_id=\"2\"),\n",
    "        AIMessage(content=\"Is the device showing any lights or indicators?\"),\n",
    "        HumanMessage(content=\"What's the temperature of the device?\")\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df719ca2",
   "metadata": {},
   "source": [
    "### HumanInTheLoop (HITL) middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6eac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def read_email(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Read an email from the given address.\"\"\"\n",
    "    # take email from state\n",
    "    return runtime.state[\"email\"]\n",
    "\n",
    "@tool\n",
    "def send_email(body: str) -> str:\n",
    "    \"\"\"Send an email to the given address with the given subject and body.\"\"\"\n",
    "    # fake email sending\n",
    "    return f\"Email sent\"\n",
    "\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "\n",
    "class EmailState(AgentState):\n",
    "    email: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model_gemini_flash,\n",
    "    tools=[read_email, send_email],\n",
    "    checkpointer=InMemorySaver(),\n",
    "     state_schema=EmailState,\n",
    "     middleware=[HumanInTheLoopMiddleware(\n",
    "        interrupt_on={\n",
    "            \"send_email\":True\n",
    "        },\n",
    "        description_prefix=\"Tool execution requires approval \"\n",
    "     )],\n",
    "     system_prompt=\"You are email assistant. Make use of read_email tool to get the email content. Come up with a response without any followup questions for additional inputs and use send_email tool to send the email\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61782ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"6\"}}\n",
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Please read my email and send a response.\")],\n",
    "        \"email\": \"Hi Seán, I'm going to be late for our meeting tomorrow. Can we reschedule? Best, John.\"\n",
    "    },\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac301b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20cc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b66fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['__interrupt__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9977b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access just the 'body' argument from the tool call\n",
    "print(response['__interrupt__'][0].value['action_requests'][0]['args']['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97598f93",
   "metadata": {},
   "source": [
    "### Approve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = agent.invoke(\n",
    "    Command( \n",
    "        resume={\"decisions\": [{\"type\": \"approve\"}]}\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c5bf9",
   "metadata": {},
   "source": [
    "### Reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "print(uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model_gpt_4o_mini,\n",
    "    tools=[read_email, send_email],\n",
    "    state_schema=EmailState,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[HumanInTheLoopMiddleware(\n",
    "        interrupt_on={\n",
    "            \"send_email\":True\n",
    "        },\n",
    "        description_prefix=\"Tool execution requires approval \"\n",
    "    )],\n",
    "    system_prompt=\"You are email assistant. Make use of read_email tool to get the email content. Come up with a response without any followup questions for additional inputs and use send_email tool to send the email\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6256ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": uuid4()}}\n",
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Please read my email and send a response.\")],\n",
    "        \"email\": \"Hi Seán, I'm going to be late for our meeting tomorrow. Can we reschedule? Best, John.\"\n",
    "    },\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a349c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9285ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['__interrupt__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = agent.invoke(Command(\n",
    "    resume={\n",
    "        \"decisions\":[{\"type\":\"reject\",\"message\":\"No, please signoff - You merciful leader, Sean\"}]\n",
    "    }\n",
    "), config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b38667",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca351c",
   "metadata": {},
   "source": [
    "### Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "    Command(        \n",
    "        resume={\n",
    "            \"decisions\": [\n",
    "                {\n",
    "                    \"type\": \"edit\",\n",
    "                    # Edited action with tool name and args\n",
    "                    \"edited_action\": {\n",
    "                        # Tool name to call.\n",
    "                        # Will usually be the same as the original action.\n",
    "                        \"name\": \"send_email\",\n",
    "                        # Arguments to pass to the tool.\n",
    "                        \"args\": {\"body\": \"This is the last straw, you're fired!\"},\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    "    )   \n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc941db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
